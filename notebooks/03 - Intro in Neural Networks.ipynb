{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "#\n",
    "# Workshop: How to develop a personalised machine learning-based application\n",
    "#\n",
    "# Notebook 3: Introduction in Neural Networks\n",
    "#\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# jupyter notebook instructions:\n",
    "# - Every cell can be executed seperately from the rest.\n",
    "# - You can execute cells in a non-sequential order (but be carefull of \n",
    "#   the dependencies between them).\n",
    "# - Execute a cell by pressing the play button or Shift+Enter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Seed the random number generator so we get the same numbers\n",
    "# every time we execute the code\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We model a single neuron with 3 input connections and one output\n",
    "# connection. We create a 3 x 1 matric and we assign random weights\n",
    "# for the input connections. The weights must have a value in the \n",
    "# [-1, 1] space, with a mean = 0\n",
    "weights = 2 * np.random.random((3, 1)) -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the sigmoid function\n",
    "def sigmoid(z):\n",
    "    return (1/(1 + np.e**(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And then its derivative. It indicates our confidence on the existing\n",
    "# weight values wi.\n",
    "def sigmoid_dz(z):\n",
    "    return (z*(1 - z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predict the result y from the given input vector X and weight W\n",
    "def predict(W, X):\n",
    "    # Reminder: The dot product equals to Σ(xi*wi)\n",
    "    return sigmoid(np.dot(X, W))\n",
    "\n",
    "\n",
    "# Train the neural network by adjusting the neuron weights\n",
    "#   Tin: The input training set, an array X of input vectors xi.\n",
    "#   Tout: A vector y with the expected output for every vector xi.\n",
    "#   w: The weights vector.\n",
    "#   n: The number of training iterations. \n",
    "def train(Tin, Tout, w, n):\n",
    "    for i in xrange(n):\n",
    "        # Pass the training set data through our network,\n",
    "        # and calculate the predicted output Pout.\n",
    "        Pout = predict(w, Tin)\n",
    "  \n",
    "        # Calculate the error as y - f(x,θ)\n",
    "        e = Tout - Pout\n",
    "\n",
    "        # Calculate the adjustment for the weights wi. The error is\n",
    "        # multiplied with the derivative of the sigmoid function.\n",
    "        # Weights with bigger error are adjusted more.\n",
    "        # Reminder: The dot product equals to Σ(Tin * (ei*Pouti))\n",
    "        d_theta = np.dot(Tin.T, e * sigmoid_dz(Pout))\n",
    "\n",
    "        w += d_theta\n",
    "        \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize the weights with random values:\n",
      " [[ 9.67299303]\n",
      " [-0.2078435 ]\n",
      " [-4.62963669]] \n",
      "\n",
      "Updated weights:\n",
      " [[ 10.38040701]\n",
      " [ -0.20641179]\n",
      " [ -4.98452047]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's try our network in action!\n",
    "print(\"Initialize the weights with random values:\\n %s \\n\" % weights)\n",
    "\n",
    "# Let's use the following training set:\n",
    "#     x0     x1    x3    y\n",
    "#     0      0     1     0\n",
    "#     1      1     1     1\n",
    "#     1      0     1     1\n",
    "#     0      1     1     0\n",
    "training_set_X = np.array([[0,0,1], [1,1,1], [1,0,1], [0,1,1]])\n",
    "training_set_y = np.array([[0, 1, 1, 0]]).T\n",
    "\n",
    "weights = train(training_set_X, training_set_y, weights, 10000)\n",
    "\n",
    "print(\"Updated weights:\\n %s \\n\" % weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0] =  0.999968966337 \n"
     ]
    }
   ],
   "source": [
    "# And let's try to make a prediction\n",
    "print \"[1, 0, 0] =  %s \" % predict(weights, np.array([1, 0, 0]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
